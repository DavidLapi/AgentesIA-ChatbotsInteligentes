# Agregar memoria al Agente de IA

El agente de IA anterior funciona bien, pero tiene un inconveniente en ese agente. No puede recordar las cosas que le pedimos anteriormente. **Por Ejemplo**, le pedimos al agente la pregunta de "쯈u칠 es IA?" y respondi칩 correctamente. Acto seguido, cuando le pedimos a la IA "쮺u치l fue la primera pregunta?" no la ha podido recordar.

Cada vez que pregunto algo, lo considera como una nueva pregunta. As칤 que, ahora mismo, el agente de IA olvida las conversaciones pasadas despu칠s de cada respuesta. Entonces, lo que haremos es **Usar la Memoria Conversacional de LangChain** (LangChain췂s Conversational Memory) para hacer un seguimiento de las interacciones.

Lo que hay que hacer es instalar primero las **dependencias de memoria**. Luego modificaremos nuestra aplicaci칩n existente para agregarle memoria. Para eso lo que vamos a hacer es:

- Volver a la terminal del sistema.

- Instalar una biblioteca llamada langchain_community --> **pip install langchain_community**

- Si recuerdas, ya la hemos instalado, pero si no lo has hecho, aseg칰rate de que est칠 instalada.

- Limpiamos la terminal --> **cls** o **clear**

- Volvemos al archivo "basic_ai_agent.py" y vamos a comentar TODO el c칩digo desde la primera l칤nea de c칩digo. Empezaremos a programar desde ah칤 arriba del todo el archivo:

```py
# 拘勇拘勇拘勇 Empezaremos el c칩digo aqu칤 拘勇拘勇拘勇

# 游댶游댶游댶 C칩digo aqu칤 游댶游댶游댶
# from langchain_ollama import OllamaLLM

# Load AI Model from Ollama
# llm = OllamaLLM(model="mistral")

# print("\nWelcome to your Agent IA! Ask me something...")

# while True:
#     question = input("Make your question (or write 'exit' to stop the machine): ")
#     if question.lower() == "exit":
#         print("Good bye, begginner!")
#         break
#     response = llm.invoke(question)
#     print("\n Response for IA: ", response)
```

1. El primer paso es importar el siguiente paquete:

```py
from langchain_community.chat_message_histories import ChatMessageHistory
```
 
Esto importar치 la clase ChatMessageHistory, que se utiliza para **almacenar y gestionar el historial del chat.** Esto permite que el modelo de IA recuerde interacciones previas en la conversaci칩n.

2. A continuaci칩n, procedemos a importar el siguiente paquete:

```py
from langchain_core.prompts import PromptTemplate
```

Esto importa una clase de plantilla de prompt que se utiliza para **definir la estructura de los prompts de IA**. Esto ayuda a formatear la entrada antes de enviarla al modelo de IA (mistral).

3. A continuaci칩n, procedemos a importar el siguiente paquete:

```py
from langchain_ollama import OllamaLLM
```

Esto es lo mismo que importamos en el anterior c칩digo. Esto importa de nuevo OllamaLLM, lo que nos permite **usar un modelo de IA a trav칠s de LangChain**. Este es el motor de IA que generar치 respuestas, as칤 que vamos a proceder a cargar el modelo de IA.

4. Cargamos el modelo de IA con el siguiente c칩digo:

```py
llm = OllamaLLM(model="mistral") # Change model to "llama3" or another if needed
```

Esto inicializa el modelo de IA mistral usando Ollama LLM, y el modelo se puede cambiar de nuevo a lo que desees (llama3, deepseek...).

5. Procederemos a inicializar la memoria del chat.

```py
# Inicialize Memory
chat_history = ChatMessageHistory() # Stores user-AI conversation history
```

Lo que hace es crear un historial de memoria de chat para almacenar el historial de conversaciones aqu칤 dentro de este historial de chat. Esto permite al chatbot llevar un registro de lo que se dijo anteriormente.

6. A continuaci칩n procedemos a definir la plantilla:

```py
# Define AI Chat Prompt
prompt = PromptTemplate(
    imput_variables=["chat_history", "question"],
    template="Previous conversation: {chat_history}\nUser: {question}\nAI:"
)
```

Esto lo que hace es definir una indicaci칩n estructurada que la IA usar치 con el *chat_history*. El historial ser치 reemplazado con el historial de conversaciones almacenado y la pregunta *question* ser치 reemplazada con la 칰ltima entrada del usuario. Esto asegura que la IA responda en contexto al ver los mensajes anteriores, as칤 que cada vez estar칤a recibiendo esos mensajes, pero sabr치 cu치l fue el historial de chat anterior. Y con base en eso har치 un seguimiento de ello.

7. A continuaci칩n escribamos la funci칩n para manejar el chat de IA con memoria:

```py
def run_chain(question):
```

Esto deine una funci칩n que procesa el chat que ocurre adelante y recupera el historial de chat normalmente.

8. Dentro de la funci칩n, escribimos lo siguiente:

```py
    # Retrieve chat history manually
    chat_history_text = "\n".join([f"{msg.type.capitalize()}: {msg.content}" for msg in chat_history.messages])
```

Estoy creando este formato para almacenar el historial de chat en un formato legible, y cada mensaje se procesa en usuario. Se almacena aqu칤 el texto del historial del chat.

9. Vamos a proceder a ejecutar la generaci칩n de respuesta de la IA:

```py
    # RUN the AI response generation
    response = llm.invoke(prompt.format(chat_history=chat_history_text, question=question))
```

Esto es parecido a llamar a "llm.invoke" que hicimos antes en la creaci칩n b치sica del agente de IA. As칤 que este ser치 mi **respuesta** (response). Esto enviar치 el **historial de chat formateado** y la **pregunta del usuario al modelo de IA**. La IA genera la respuesta considerando los mensajes anteriores y la pasa a la respuesta.

10. Vamos a almacenar la nueva entrada del usuario y la respuesta de la IA en la memoria:

```py
    # Store new user input and AI response in memory
    chat_history.add_user_message(question)
    chat_history.add_ai_message(response)
```

"chat_history" guarda la pregunta del usuario y la respuesta de la IA en el historial de chat. Esto asegura que la IA recuerde los mensajes pasados en futuras respuestas.

11. Finalmente, dir칠 "devolver respuesta":

```py
    return response
```

Esto devolver치 la respuesta generada por la IA para ser mostrada en el chat.

---

Ahora vamos a proceder a crear el bucle interactivo del chatbot.

```py
# Primero imprimiremos un mensaje de bienvenida
print("\n游닋 AI Chatbot with Memory")
print("Type 'exit' to stop.")
# Iniciamos un bucle infinito hasta que el usuario salga del chat
while True:
    # Entrada de usuario input
    user_input = input("\n游늶 You: ")
    # Condicion if si la entrada de usuario es igual a 'exit'
    if user_input.lower() == "exit":
        # Imprimimos Goob Bye y terminamos el bucle 'break'
        print("\n游녦 Good Bye!!")
        break

    # Llamamos la funci칩n run_chain con la nueva entrada de usuario
    ai_response = run_chain(user_input)
    # Imprimimos la respuesta de la IA
    print(f"\n游닏 AI: {ai_response}")
```

Esta es toda nuestra aplicaci칩n con memoria incorporada, as칤 que vamos a seguir adelante con la terminal, y ejecutar la misma aplicaci칩n de nuevo:

```bash
C:\Users\alumno\Desktop\AIAgents\Day1> py basic_ai_agent.py

# Resultado:
游닋 AI Chatbot with Memory
Type 'exit' to stop.

游늶 You: 

```

Le vamos a preguntar: "What is AI Agent?" (쯈u칠 es un agente de IA?) El proceso ser칤a el mismo, pero recordar치 la primera pregunta y lo guardar치 en la memoria. El resultado ser칤a algo as칤:

![RespuestaIA](./img/ResponseAI_1.png)

Ahora vamos a preguntar: "Who invented AI?" (쯈ui칠n invent칩 la IA?). Veamos qu칠 dice:

![RespuestaIA](./img/ResponseAI_2.png)

Ahora preguntamos: Can it learn by itself? (쯇uede aprender por s칤 mismo?). Veamos qu칠 dice:

![RespuestaIA](./img/ResponseAI_3.png)

Ahora le preguntamos: "What was the first question I asked?* (쮺ual fue la primera pregunta que he preguntado?). Veamos que dice:

![RespuestaIA](./img/ResponseAI_4.png)

Tu pregunta fue: "Qu칠 es un agente de IA?" Si recuerdas, esa fue nuestra primera pregunta. Ahora lo recuerda. As칤 que tiene un poco el contexto de lo que estoy haciendo. Y de alguna manera retoma la siguiente sesi칩n con ese contexto. As칤 que lo que sea que preguntes, puedes tener una conversaci칩n normal con este agente de IA.

Y finalmente puedo simplemente salir "exit" y se escapa de eso:

![RespuestaIA](./img/ResponseAI_5.png)

 
As칤 que eso es nuestro a침adido. As칤 es c칩mo puedes a침adir memoria a tu agente de IA. As칤 que de nuevo, si tuviste alg칰n problema o inconveniente con esto, h치zmelo saber en los mensajes.

Anterior --> [**Click aqu칤**](./01d_ConstruirAgenteIASimple.md)

Siguiente --> [**Click aqu칤**](./01f_Interfazweb.md)