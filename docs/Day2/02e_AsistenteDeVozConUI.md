# Crear un Asistente de Voz de IA Basado en Web

Vamos a proceder a crear un **asistente de voz basado en la web**. Esta vez crearemos un nuevo archivo llamado *ai_voice_assistant_ui.py*.

## C贸mo funciona el asistente de voz de IA basado en la web

Antes de escribir c贸digo, vamos a entender qu茅 hace nuestro asistente de voz en la web:

- El usuario hace click en el bot贸n de "Start Listening" en la interfaz web.

- La IA escucha la voz del usuario y la convierte en texto.

- La IA procesa la consulta usando *Ollama*.

- La IA responde y pronuncia la respuesta.

- El historial de chat se muestra en la interfaz.

Esta vez tendremos una mejor interfaz que puede ser presentada a otra persona o a帽adida como un proyecto en tu portafolio.

Entonces sigamos adelante y escribamos el c贸digo. Una vez escrito el c贸digo, ejecutaremos el siguiente comando para arrancar el asistente de voz de IA basado en web usando la aplicaci贸n *Streamlit*:

```bash
streamlit run ai_voice_assistant_ui.py
```

Para empezar, nos dirigiremos a nuestro s铆mbolo de sistema con la ruta del d铆a 2 (C:\Users\alumno\Desktop\AIAgents\Day2>). 

Desde nuestra carpeta crearemos un nuevo archivo, cuya mayor parte del c贸digo ser谩 similar al anterior asistente de voz, pero lo crearemos de todos modos. Lo llmaremos "ai_voice_assistant_ui.py".

C贸mo se mencion贸 antes, la mayor parte del c贸digo ser谩 el mismo, porque la l贸gica es exactamente la misma. As铆 que vamos a intentar resumirlo un poco desde el principio para que sea bastante f谩cil de entender basado en lo que hicimos en el otro archivo.

Vamos a empezar por importar los siguientes m贸dulos:

```py
import streamlit as st
import speech_recognition as sr
import pyttsx3
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.prompts import PromptTemplate
from langchain_ollama import OllamaLLM
```

A continuaci贸n vamos a proceder a crear nuestro motor de arranque para el modelo de IA:

```py
# Load AI Model
llm = OllamaLLM(model="mistral") # Change to "llama3" or another Ollama model
```

Luego iniciaremos la memoria en el historial de chat:

```py
# Initialize Memory (LangChain v1.0+)
if "chat_history" not in st.session_state:
    st.session_state.chat_history = ChatMessageHistory() # Stores user-AI conversation history
```

Le decimos que si "chat_history" no est谩 en el estado de sesi贸n en Streamlit, se va a crear uno similar a lo que hicimos antes.

A continuaci贸n, inicializamos el motor de texto a voz:

```py
# Initialize Text-to-Speech Engine
engine = pyttsx3.init()
engine.setProperty("rate", 160) # Adjust speaking speed
```

A continuaci贸n a帽adiremos el reconocimiento de voz:

```py
# Speech Recognition
recognizer = sr.Recognizer()
```

Despu茅s a帽adiremos la funci贸n "speak" para que hable la m谩quina:

```py
# Function to Speak
def speak(text):
    engine.say(text)
    engine.runAndWait()
```

A continuaci贸n, escribiremos la funci贸n para escuchar:

```py
# Function to Listen
def listen():
    with sr.Microphone() as source:
        st.write("\n Listening...")
        recognizer.adjust_for_ambient_noise(source)
        audio = recognizer.listen(source)
    try:
        query = recognizer.recognize_google(audio)
        st.write(f" You Said: {query}")
        return query.lower()
    except sr.UnknownValueError:
        st.write(" Sorry, I couldn`t understand. Try again!")
        return ""
    except sr.RequestError:
        st.write("ｏ Speech Recognition Service Unavailable")
        return ""
```

Aqu铆 vemos que la funci贸n "listen" no cambia mucho, s贸lo que las l铆neas 3, 8, 11 y 14 de la funci贸n se cambian las funciones "print" por "st.write" para que Streamlit imprima por texto los resultados en la web.

A continucaci贸n vamos a definir nuestro mensaje de chat de IA.

```py
# AI Chat Prompt
prompt = PromptTemplate(
    imput_variables=["chat_history", "question"],
    template="Previous conversation: {chat_history}\nUser: {question}\nAI:",
)
```

Ahora escribiremos la funci贸n para procesar las respuestas de la IA:

```py
# Function to Process AI Responses
def run_chain(question):
    # Retrieve past chat history manually
    chat_history_text = "\n".join([f"{msg.type.capitalize()}: {msg.content}" for msg in st.session_state.chat_history.messages])

    # RUN the AI response generation
    response = llm.invoke(prompt.format(chat_history=chat_history_text, question=question))

    # Store new user input and AI response in memory
    st.session_state.chat_history.add_user_message(question)
    st.session_state.chat_history.add_ai_message(response)

    return response
```

Ahora vamos a dise帽ar nuestra interfaz web de Streamlit. Primero vamos a escribir un t铆tulo que muestre la interfaz web del asistente de voz de IA, y un p谩rrafo que describe su prop贸sito:

```py
# Streamlit Web UI
st.title(" AI Voice Assistant (Web UI)")
st.write(" Click the button below to speak to your AI assistant!")
```

En "st.write" nos pone que hagammos click en el bot贸n de abajo para hablar con sus asistente de IA. Este es ell bot贸n para grabar la entrada de voz:

```py
# Button to Record Voice Input
if st.button(" Start Listening"):
    user_query = listen()
```

Esto comenzar谩 tan pronto como el usuario presione ese bot贸n, comenzar谩 a escuchar y escuchar谩 a la consulta del usuario. 

Dentro de la funci贸n "if" a帽adiremos esto:

```py
    if user_query:
        ai_response = run_chain(user_query)
        st.write(f"**You** {user_query}")
        st.write(f"**AI:** {ai_response}")
        speak(ai_response) # AI speaks the response
```

Si la consulta del usuario est谩 presente (if user_query:) escribir茅 que la respuesta de la IA ejecuta la cadena de consulta del usuario (ai_response = run_chain(user_query)). 

Lo que sea que dijimos la consulta del usuario se muestra al usuario (st.write(f"**You** {user_query}")). 

A continuaci贸n lo que sea por el usuario diga, voy a mostrar esa respuesta (st.write(f"**AI:** {ai_response}")).

Y despu茅s escribimos "Habla la respuesta de la IA" (speak(ai_response)) que surge finalmente.

Al final mostraremos el historial completo del chat:

```py
# Display Full Chat History
st.subheader(" Chat History")
for msg in st.session_state.chat_history.messages:
    st.write(f"**{msg.type.capitalize()}**: {msg.content}")
```

Pondremos un encabezado (st.subheader(" Chat History")) para el historial del chat. Despu茅s haremos un bucle con los mensajes almacenados (for msg in st.session_state.chat_history.messages:). Nos escribir谩 los mensajes (st.write(f"**{msg.type.capitalize()}**: {msg.content}")) capitalizando la primera letra.

As铆 que esa es toda nuestra aplicaci贸n donde se ejecutar谩 en una interfaz web. 

As铆 que empezaremos a ejecutarla con el comando mencionado antes:

```bash
streamlit run ai_voice_assistant_ui.py
```

Una vez ejecutado, se nos abre el navegador y la terminal se ver铆a parecido a esto:

```bash
PS C:\Users\alumno\Desktop\AIAgents\Day2> streamlit run .\ai_voice_assistant_ui.py

  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://x.x.x.x:8501 # <-- Tu direcci贸n IP

```

En el navegador, nos saldr铆a algo as铆:

![RespuestaIA](./img/web_ui_ai_voice1.png)

Para usarlo, s贸lo debemos pulsar el bot贸n y preguntar: "what is ia?". Esperamos un momento y nos saldr铆a as铆:

![RespuestaIA](./img/web_ui_ai_voice2.png)

Con esta primera pregunta nos lo almacenar谩 en el historial del chat. Ahora preguntamos: "who is Freddy Mercury?":

![RespuestaIA](./img/web_ui_ai_voice3.png)

Y listo! Ya nos lo guarda las preguntas que le hagamos en el historial del chat y con esto concluye nuestra aplicaci贸n 

Espero que lo hayas conseguido y hayas llegado hasta aqu铆.

D铆a siguiente --> [**Click aqu铆**](../Day3/03_Intro.md)

Anterior --> [**Click aqu铆**](./02d_EjecutarAsistente.md)